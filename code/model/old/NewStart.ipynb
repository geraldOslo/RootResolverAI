{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbacc46f-1aa1-4132-b74c-2be3f3d83293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "431034d1-f79c-41b6-8bc6-9de5c97ad8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directory and CSV file paths\n",
    "system = \"jupyter\"\n",
    "data = \"dag\"\n",
    "\n",
    "if system == \"linux\":\n",
    "    data_dir = \"/fp/homes01/u01/ec-gerald/My Projects/ec192/data/endo-radiographs/clips\"\n",
    "elif system == \"win\":\n",
    "    data_dir = r\"\\\\aspasia.ad.fp.educloud.no\\ec192\\data\\endo-radiographs\\clips\"\n",
    "elif system == \"jupyter\":\n",
    "    if data == \"dag\":\n",
    "        data_dir = \"/fp/projects01/ec192/data/endo-radiographs/dag/clips\"\n",
    "    elif data == \"deniz\":\n",
    "        data_dir = \"/fp/projects01/ec192/data/endo-radiographs/deniz/clips\"\n",
    "csv_file = 'codefile.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a8f466-0a61-4b61-b93a-0e27397a09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    df = pd.read_csv(os.path.join(data_dir, \"codefile.csv\"))\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        img = Image.open(os.path.join(data_dir, row['filename']))\n",
    "        img = img.resize((256, 256))\n",
    "        img = np.array(img)\n",
    "        img = img.reshape((256, 256, 1))  # Reshape to add the channel dimension\n",
    "        images.append(img)\n",
    "\n",
    "        # Subtract 1 from the label to make them 0-based (i.e., from 1-5 to 0-4)\n",
    "        labels.append(row['prediction'] - 1)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X, y = load_data(data_dir)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y = to_categorical(y, num_classes=5)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a53779-61f2-4f25-8e43-fff2ec1bc127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(256, 256, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))  # output layer with 5 nodes\n",
    "\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd64037-44c4-449b-bef1-a3abd791898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 14:43:03.546753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 24s 405ms/step - loss: 11.7059 - accuracy: 0.3836 - val_loss: 1.6068 - val_accuracy: 0.4341\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 22s 387ms/step - loss: 1.6053 - accuracy: 0.4155 - val_loss: 1.6036 - val_accuracy: 0.4341\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 23s 402ms/step - loss: 1.6021 - accuracy: 0.4177 - val_loss: 1.6003 - val_accuracy: 0.4341\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 22s 378ms/step - loss: 1.6002 - accuracy: 0.4177 - val_loss: 1.5971 - val_accuracy: 0.4341\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 23s 400ms/step - loss: 1.8488 - accuracy: 0.4172 - val_loss: 1.5940 - val_accuracy: 0.4341\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 22s 381ms/step - loss: 1.5927 - accuracy: 0.4172 - val_loss: 1.5908 - val_accuracy: 0.4341\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 22s 387ms/step - loss: 1.5895 - accuracy: 0.4155 - val_loss: 1.5877 - val_accuracy: 0.4341\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 23s 391ms/step - loss: 1.5867 - accuracy: 0.4133 - val_loss: 1.5846 - val_accuracy: 0.4341\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 21s 367ms/step - loss: 1.5835 - accuracy: 0.4144 - val_loss: 1.5816 - val_accuracy: 0.4341\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 24s 416ms/step - loss: 1.5805 - accuracy: 0.4155 - val_loss: 1.5786 - val_accuracy: 0.4341\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 25s 428ms/step - loss: 1.5775 - accuracy: 0.4150 - val_loss: 1.5756 - val_accuracy: 0.4341\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 23s 396ms/step - loss: 1.5745 - accuracy: 0.4150 - val_loss: 1.5726 - val_accuracy: 0.4341\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 23s 403ms/step - loss: 1.5717 - accuracy: 0.4139 - val_loss: 1.5697 - val_accuracy: 0.4341\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 23s 407ms/step - loss: 1.5687 - accuracy: 0.4161 - val_loss: 1.5668 - val_accuracy: 0.4341\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 22s 387ms/step - loss: 1.5659 - accuracy: 0.4177 - val_loss: 1.5640 - val_accuracy: 0.4341\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 24s 415ms/step - loss: 1.5629 - accuracy: 0.4177 - val_loss: 1.5611 - val_accuracy: 0.4341\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 25s 438ms/step - loss: 1.5604 - accuracy: 0.4150 - val_loss: 1.5583 - val_accuracy: 0.4341\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 23s 399ms/step - loss: 1.5575 - accuracy: 0.4150 - val_loss: 1.5555 - val_accuracy: 0.4341\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 22s 386ms/step - loss: 1.5547 - accuracy: 0.4166 - val_loss: 1.5528 - val_accuracy: 0.4341\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 24s 413ms/step - loss: 1.5518 - accuracy: 0.4161 - val_loss: 1.5500 - val_accuracy: 0.4341\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 23s 400ms/step - loss: 1.5494 - accuracy: 0.4161 - val_loss: 1.5473 - val_accuracy: 0.4341\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 23s 400ms/step - loss: 1.5464 - accuracy: 0.4188 - val_loss: 1.5446 - val_accuracy: 0.4341\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 22s 389ms/step - loss: 1.5439 - accuracy: 0.4188 - val_loss: 1.5419 - val_accuracy: 0.4341\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 21s 373ms/step - loss: 1.5417 - accuracy: 0.4161 - val_loss: 1.5393 - val_accuracy: 0.4341\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "def add_noise(img):\n",
    "    '''Add random noise to an image'''\n",
    "    VARIABILITY = 50\n",
    "    deviation = VARIABILITY*random.random()\n",
    "    noise = np.random.normal(0, deviation, img.shape)\n",
    "    img += noise\n",
    "    np.clip(img, 0., 255.)\n",
    "    return img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Rotate images up to 10 degrees\n",
    "    zoom_range=0.1,  # Zoom in/out up to 10%\n",
    "    horizontal_flip=True,  # Allow horizontal flipping\n",
    "    fill_mode='nearest',  # Fill in newly created pixels\n",
    "    preprocessing_function=add_noise  # Add noise\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) // 32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=50)\n",
    "\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(history.history['accuracy'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Accuracy', fontsize=10)\n",
    "plt.title('Accuracy Curves', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f07b3-2a51-4fbe-9889-466d1edd0d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv-kernel",
   "language": "python",
   "name": "mlenv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
