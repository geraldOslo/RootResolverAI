{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d00b20",
   "metadata": {},
   "source": [
    "# PAI Scoring on radiographs\n",
    "\n",
    "## Data\n",
    "Radiographs are provided as 8 bit grayscale image clips 256x256 pixels centered on the apex. Each file has a label with the PAI scored by a human person. Later we will add on weigthtings for the humans compentence level because some scorings are done by undergraduate dentistry students.\n",
    "\n",
    "## Todo\n",
    "This version works on a limited set by one specialist candidate and overperforms. Have to change it to use the bigger database we have available with more thant 2 000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb96643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:54:30.262810: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Do not show warnings\n",
    "system = \"jupyter\"\n",
    "data = \"dag\"\n",
    "print(\"all loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c96ee1-0889-4b06-a9a5-ccfe6f968a0a",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe49cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your directory and CSV file paths\n",
    "if system == \"linux\":\n",
    "    data_dir = \"/fp/homes01/u01/ec-gerald/My Projects/ec192/data/endo-radiographs/clips\"\n",
    "elif system == \"win\":\n",
    "    data_dir = r\"\\\\aspasia.ad.fp.educloud.no\\ec192\\data\\endo-radiographs\\clips\"\n",
    "elif system == \"jupyter\":\n",
    "    if data == \"dag\":\n",
    "        data_dir = \"/fp/projects01/ec192/data/endo-radiographs/dag/clips\"\n",
    "    elif data == \"deniz\":\n",
    "        data_dir = \"/fp/projects01/ec192/data/endo-radiographs/deniz/clips_balanced\"\n",
    "    \n",
    "    \n",
    "csv_file = os.path.join(data_dir, \"codefile.csv\")\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# load the CSV file using pandas\n",
    "df = pd.read_csv(csv_file)\n",
    "df.columns = ['filename', 'prediction']\n",
    "\n",
    "# convert labels to str because ImageDataGenerator treats all inputs as strings\n",
    "df['prediction'] = df['prediction'].astype(str)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# create ImageDataGenerators for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# specify your target image size (this will be the input shape for your CNN)\n",
    "target_size = (image_size, image_size)\n",
    "\n",
    "# specify batch size\n",
    "batch_size = 64  \n",
    "\n",
    "# create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=data_dir,\n",
    "    x_col=\"filename\",  # this might be \"image_name\" or something similar depending on your CSV\n",
    "    y_col='prediction',  # this might be \"diagnosis\" or something similar depending on your CSV\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # use 'categorical' since we have now one-hot encoded labels\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    directory=data_dir,\n",
    "    x_col=\"filename\",  # this might be \"image_name\" or something similar depending on your CSV\n",
    "    y_col='prediction',  # this might be \"diagnosis\" or something similar depending on your CSV\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # use 'categorical' since we have now one-hot encoded labels\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data:\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to get filenames from the generator\n",
    "def get_filenames(generator):\n",
    "    return generator.filenames\n",
    "\n",
    "# Function to get class indices\n",
    "def get_class_indices(generator):\n",
    "    return generator.classes\n",
    "\n",
    "# Fetch filenames and class indices for training and validation sets\n",
    "train_filenames = get_filenames(train_generator)\n",
    "train_class_indices = get_class_indices(train_generator)\n",
    "\n",
    "valid_filenames = get_filenames(valid_generator)\n",
    "valid_class_indices = get_class_indices(valid_generator)\n",
    "\n",
    "# Get the class labels from class indices\n",
    "label_map = (train_generator.class_indices)\n",
    "inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "train_labels = [inverse_label_map[index] for index in train_class_indices]\n",
    "valid_labels = [inverse_label_map[index] for index in valid_class_indices]\n",
    "\n",
    "# Modified plot function to include file names and labels\n",
    "def plot_images_with_labels(images, filenames, labels, title):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(8,8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in np.arange(0, 16):\n",
    "        axes[i].imshow(images[i].reshape(target_size), cmap='gray')\n",
    "        axes[i].set_title(f\"{filenames[i]}: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "        #print(filenames[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # adjust the top spacing\n",
    "    plt.suptitle(title, fontsize=16)  # use suptitle for better positioning\n",
    "    plt.show()\n",
    "\n",
    "# Plot images with labels\n",
    "train_images, _ = next(train_generator)  # Get a batch of images from the generator\n",
    "valid_images, _ = next(valid_generator)\n",
    "\n",
    "plot_images_with_labels(train_images, train_filenames, train_labels, 'Training Images')\n",
    "print(\"\\n\\n\")\n",
    "plot_images_with_labels(valid_images, valid_filenames, valid_labels, 'Validation Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71723355",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4516e-f3dc-403e-a7db-6a76303184aa",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "The following code is used to tune hyperparameters and find the most suitable model. Might need:\n",
    "pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7b87f-56d7-4b0b-b7d9-fa19643815f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Defines the parameters to be tuned\n",
    "def model_builder(hp):\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "  hp_layer_1 = hp.Int('layer_1', min_value=1, max_value=1000, step=100)\n",
    "  hp_layer_2 = hp.Int('layer_2', min_value=1, max_value=1000, step=100)\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(units=hp_layer_1, activation=hp_activation))\n",
    "  model.add(tf.keras.layers.Dense(units=hp_layer_2, activation=hp_activation))\n",
    "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='dir',\n",
    "                     project_name='x')\n",
    "\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Define the number of steps per epoch\n",
    "train_steps_per_epoch = len(train_df) // batch_size\n",
    "valid_steps_per_epoch = len(valid_df) // batch_size\n",
    "\n",
    "# Train the tuner\n",
    "tuner.search(train_generator,\n",
    "             validation_data=valid_generator,\n",
    "             epochs=50,\n",
    "             steps_per_epoch=train_steps_per_epoch,\n",
    "             validation_steps=valid_steps_per_epoch,\n",
    "             callbacks=[stop_early])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_steps_per_epoch,\n",
    "    callbacks=[early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813c03d-f30d-483f-92de-2d0cce60a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a6816-e1cf-4a12-b890-bbcd3a78d0fb",
   "metadata": {},
   "source": [
    "### Code from ChatGPT\n",
    "\n",
    "Hyperparameters are the knobs that you tune to optimize your model performance. Some common hyperparameters in a Convolutional Neural Network (CNN) include:\n",
    "\n",
    "    Number of layers\n",
    "    Number of nodes (neurons) per layer\n",
    "    Activation function\n",
    "    Optimizer\n",
    "    Learning rate\n",
    "    Dropout rate\n",
    "    Batch size\n",
    "    Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b9a7e-e7db-4753-9eaf-d19b75b4da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Convolutional layers\n",
    "    # The number of convolutional layers is a hyperparameter ranging from 2 to 5\n",
    "    for i in range(hp.Int('conv_layers', 2, 5)):\n",
    "        model.add(layers.Conv2D(hp.Int(f'conv_{i}_units',\n",
    "                                       min_value=32,\n",
    "                                       max_value=256,\n",
    "                                       step=32), \n",
    "                                (3, 3), \n",
    "                                activation='relu'))\n",
    "        # Following each Conv layer with a MaxPool layer\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flattening the output from the convolutional layers so it can be input to the dense layers\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Dense layers\n",
    "    # The number of dense layers is a hyperparameter ranging from 2 to 5\n",
    "    for i in range(hp.Int('dense_layers', 2, 5)):\n",
    "        model.add(layers.Dense(hp.Int(f'dense_{i}_units',\n",
    "                                      min_value=32,\n",
    "                                      max_value=256,\n",
    "                                      step=32), \n",
    "                               activation=hp.Choice(f'dense_{i}_activation', \n",
    "                                                    values=['relu', 'tanh', 'sigmoid'])))\n",
    "        # Optional: Adding a Dropout layer after each Dense layer for regularization\n",
    "        if i < hp.Int('dense_layers', 2, 5) - 1:\n",
    "            model.add(layers.Dropout(hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer with 5 units, one for each class\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    # Compiling the model\n",
    "    # The learning rate is a hyperparameter, specified on a log scale\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "                      hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Defining the tuner\n",
    "tuner = RandomSearch(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_trials=10,  # The number of different models to try\n",
    "                     directory='my_dir',\n",
    "                     project_name='hyperparam_tuning')\n",
    "\n",
    "# Displaying a summary of the search space\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Performing the hyperparameter search\n",
    "# Replace x, y, val_x, val_y with your actual data\n",
    "tuner.search(x, y, epochs=10, validation_data=(val_x, val_y))\n",
    "\n",
    "# Displaying a summary of the search results\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c47d4-2fc0-4899-ad19-44eaf680b175",
   "metadata": {},
   "source": [
    "# Models\n",
    "Different models ar used:\n",
    "- simple CNN model\n",
    "- VGG16 based custom model for 8-bit greyscale images\n",
    "- VGG19 pretrained model - transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ecc9c-357f-4e99-a6ba-82cfd342a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 Transfer learning\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "pretrained = VGG19(include_top=False, input_shape=(224, 224, 3), \n",
    "                   weights='imagenet', pooling='max')\n",
    "inputs = pretrained.input\n",
    "\n",
    "for layer in pretrained.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Add fitting structure of dense layers:\n",
    "hidden = Dense(128, activation='relu')(outputs)\n",
    "dropout = Dropout(.3)(hidden)\n",
    "hidden2 = Dense(128, activation='relu')(dropout)\n",
    "dropout2 = Dropout(.3)(hidden2)\n",
    "preds = Dense(5, activation='softmax')(dropout2)\n",
    "\n",
    "model = Model(inputs, preds)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Run the model:\n",
    "batch_size = 32\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input, horizontal_flip=True)\n",
    "train_batches = train_generator.flow_from_directory(train_dir,\n",
    "                                                    target_size=(224, 224), \n",
    "                                                    batch_size=batch_size)\n",
    "\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input, horizontal_flip=True)\n",
    "val_batches = val_generator.flow_from_directory(val_dir,\n",
    "                                                target_size=(224, 224),\n",
    "                                                batch_size=batch_size)\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=val_batches,\n",
    "          steps_per_epoch=len(train_batches), \n",
    "          validation_steps=len(val_batches))\n",
    "\n",
    "# Function to reverse preprocessing images for view:\n",
    "def deprocess_vgg19(x):\n",
    "    x[..., 0] += 103.939\n",
    "    x[..., 1] += 116.779\n",
    "    x[..., 2] += 123.68\n",
    "    x = x[..., ::-1]  # Convert BGR to RGB\n",
    "    x = np.clip(x, 0, 255).astype('uint8')  # Clip values to range [0, 255]\n",
    "    return x\n",
    "\n",
    "# Test the model:\n",
    "\n",
    "n = 8\n",
    "i = 1\n",
    "for X, y in val_batches:\n",
    "    preds = model.predict(X)\n",
    "    preds = preds[1]\n",
    "    true_label = labels[np.argmax(y)]\n",
    "    label = labels[np.argmax(preds)]\n",
    "    probability = preds[np.argmax(preds)]\n",
    "    print(true_label + \" Predicted: \" + label + \"; \" + str(probability))\n",
    "    # decoded_preds = decode_predictions(preds, top=1)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    img = X[0].astype(np.uint8)\n",
    "    img = deprocess_vgg19(X[0])\n",
    "    # label = labels[np.argmax(y[0])]\n",
    "    # predicted = decoded_preds[0]\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    # fig.suptitle('Truth: {}, Predicted: {}'.format(label, predicted))\n",
    "    plt.show()\n",
    "    print(i)\n",
    "    if i > n: \n",
    "      break\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1effc89-4539-4892-8d0a-35cda5af182f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
