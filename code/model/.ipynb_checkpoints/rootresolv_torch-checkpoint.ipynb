{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf91390-1d30-4e54-9760-7c9530fcbaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f146af-aae6-4d92-94d7-2484d624e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directory and CSV file paths\n",
    "system = \"jupyter\"\n",
    "data = \"deniz\"\n",
    "\n",
    "if system == \"linux\":\n",
    "    data_dir = \"/fp/homes01/u01/ec-gerald/My Projects/ec192/data/endo-radiographs/clips\"\n",
    "elif system == \"win\":\n",
    "    data_dir = r\"\\\\aspasia.ad.fp.educloud.no\\ec192\\data\\endo-radiographs\\clips\"\n",
    "elif system == \"jupyter\":\n",
    "    if data == \"dag\":\n",
    "        data_dir = \"/fp/projects01/ec192/data/endo-radiographs/dag/clips\"\n",
    "    elif data == \"deniz\":\n",
    "        data_dir = \"/fp/projects01/ec192/data/endo-radiographs/deniz/clips\"\n",
    "\n",
    "csv_file = os.path.join(data_dir, 'codefile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae092b6-34fa-4473-b4e8-d0dc127fed58",
   "metadata": {},
   "source": [
    "Define a custom dataset class that loads images and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc5dc2e-608e-420a-9b42-c3ef028c3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, csv_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_info = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_dir, self.data_info.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('L')  # Load as grayscale\n",
    "        label = int(self.data_info.iloc[idx, 1])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52de6f2-e86a-47cb-9236-416a480d3bbd",
   "metadata": {},
   "source": [
    "Define data transformations. Since your images are 8-bit grayscale, you can normalize them to the range [0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5788940-f917-427d-a1c6-d0e461b81118",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize all images to 256x256\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d194f14a-0eb0-403a-b8f2-b6b399e65cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = CustomDataset(data_dir=data_dir, csv_file=csv_file, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = train_test_split(custom_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "batch_size = 64  # Adjust as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c252ea-1b00-4d48-accd-6848089ded95",
   "metadata": {},
   "source": [
    "Create a data loader to iterate through your dataset in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132626b7-6e54-42bc-aa79-31a0b837e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 1, 256, 256])\n",
      "Labels: tensor([3, 1, 4, 3, 3, 4, 3, 3, 2, 3, 3, 3, 4, 3, 3, 3, 1, 3, 3, 3, 4, 2, 3, 3,\n",
      "        3, 2, 3, 2, 3, 3, 3, 1, 4, 4, 3, 3, 2, 3, 4, 3, 2, 3, 3, 3, 4, 3, 3, 4,\n",
      "        3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 1, 3, 1, 3])\n",
      "Input shape: torch.Size([64, 1, 256, 256])\n",
      "Labels: tensor([3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 4, 3, 3, 3,\n",
      "        3, 4, 3, 3, 4, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 2, 1, 3, 1, 4])\n",
      "Input shape: torch.Size([64, 1, 256, 256])\n",
      "Labels: tensor([3, 3, 3, 3, 3, 3, 3, 1, 5, 3, 3, 3, 3, 3, 5, 3, 4, 1, 3, 1, 1, 3, 3, 3,\n",
      "        3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 4, 3, 3, 3, 4, 5, 3, 3, 3, 3,\n",
      "        3, 3, 1, 3, 1, 3, 3, 3, 3, 1, 3, 1, 3, 4, 2, 3])\n",
      "Input shape: torch.Size([64, 1, 256, 256])\n",
      "Labels: tensor([3, 3, 4, 3, 3, 3, 3, 1, 5, 3, 4, 3, 3, 5, 3, 3, 5, 2, 3, 1, 4, 4, 3, 4,\n",
      "        2, 4, 3, 3, 1, 3, 4, 3, 4, 3, 3, 2, 3, 4, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3,\n",
      "        2, 1, 2, 1, 3, 3, 3, 4, 3, 3, 5, 5, 5, 3, 3, 3])\n",
      "Input shape: torch.Size([28, 1, 256, 256])\n",
      "Labels: tensor([1, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 4, 3, 1, 3, 3, 4, 3, 4,\n",
      "        1, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print(\"Input shape:\", inputs.shape)\n",
    "    print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a8d16-3645-4250-a67a-588612b6a5b6",
   "metadata": {},
   "source": [
    "Here's a breakdown of the layers in this network:\n",
    "\n",
    "    self.conv1: The first convolutional layer with 16 output channels, a 3x3 kernel size, and padding to maintain spatial dimensions.\n",
    "\n",
    "    self.pool: Max-pooling layer with a 2x2 kernel and stride 2, which reduces the spatial dimensions by a factor of 2.\n",
    "\n",
    "    self.conv2: The second convolutional layer with 32 output channels, a 3x3 kernel size, and padding.\n",
    "\n",
    "    self.fc1: The first fully connected layer with 128 neurons. The input size is calculated based on the spatial dimensions after max-pooling. You should adjust this size according to your image dimensions.\n",
    "\n",
    "    self.fc2: The second fully connected layer with the output size set to num_classes, which is 5 in your case.\n",
    "\n",
    "    The forward method defines the forward pass of the network, including ReLU activation functions after convolutional layers and log softmax activation in the final layer for classification.\n",
    "\n",
    "You can create an instance of this model and use it for training your image classification task. Make sure to adjust the input size in self.fc1 based on your specific image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97acf78-0723-45c2-bd1c-3be6396911d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 64, 128)  # Adjust input size based on your image size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 64 * 64)  # Adjust the size based on your image size\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x  # No need for log_softmax here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90620e44-ac79-434b-a639-0cbb6becf779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Training Loss: 1.320275616645813, Validation Loss: 1.1111982464790344\n",
      "Epoch 2/50, Training Loss: 1.1168975472450255, Validation Loss: 1.0137264132499695\n",
      "Epoch 3/50, Training Loss: 1.0263814687728883, Validation Loss: 0.948823481798172\n",
      "Epoch 4/50, Training Loss: 1.0610478401184082, Validation Loss: 0.9815311431884766\n",
      "Epoch 5/50, Training Loss: 1.0492495894432068, Validation Loss: 1.0320023596286774\n",
      "Epoch 6/50, Training Loss: 1.0095237731933593, Validation Loss: 0.9851496815681458\n",
      "Epoch 7/50, Training Loss: 1.0030179381370545, Validation Loss: 1.0005922615528107\n",
      "Epoch 8/50, Training Loss: 1.0648724555969238, Validation Loss: 0.9826919436454773\n",
      "Epoch 9/50, Training Loss: 0.9954907417297363, Validation Loss: 1.0408519506454468\n",
      "Epoch 10/50, Training Loss: 1.0375580191612244, Validation Loss: 0.9896040856838226\n",
      "Epoch 11/50, Training Loss: 1.0090795874595642, Validation Loss: 1.0206328928470612\n",
      "Epoch 12/50, Training Loss: 0.9612010836601257, Validation Loss: 0.9764902889728546\n",
      "Epoch 13/50, Training Loss: 0.996534013748169, Validation Loss: 1.0203793942928314\n",
      "Epoch 14/50, Training Loss: 0.9375173926353455, Validation Loss: 1.0540463328361511\n",
      "Epoch 15/50, Training Loss: 0.9522295236587525, Validation Loss: 0.9989509284496307\n",
      "Epoch 16/50, Training Loss: 0.9345615148544312, Validation Loss: 0.9912032783031464\n",
      "Epoch 17/50, Training Loss: 0.9950785994529724, Validation Loss: 1.0176912546157837\n",
      "Epoch 18/50, Training Loss: 0.9173710465431213, Validation Loss: 1.0255760550498962\n",
      "Epoch 19/50, Training Loss: 0.9637842297554016, Validation Loss: 1.0177816152572632\n",
      "Epoch 20/50, Training Loss: 0.934736680984497, Validation Loss: 1.0234612226486206\n",
      "Epoch 21/50, Training Loss: 0.9398352622985839, Validation Loss: 1.0003664195537567\n",
      "Epoch 22/50, Training Loss: 0.9208913326263428, Validation Loss: 1.031177967786789\n",
      "Epoch 23/50, Training Loss: 0.8754114270210266, Validation Loss: 1.0270864963531494\n",
      "Epoch 24/50, Training Loss: 0.889866030216217, Validation Loss: 1.0325396955013275\n",
      "Epoch 25/50, Training Loss: 0.8887948036193848, Validation Loss: 1.013748973608017\n",
      "Epoch 26/50, Training Loss: 0.8579594016075134, Validation Loss: 1.044637531042099\n",
      "Epoch 27/50, Training Loss: 0.8809218883514405, Validation Loss: 1.0296945869922638\n",
      "Epoch 28/50, Training Loss: 0.8683791995048523, Validation Loss: 1.0387763679027557\n",
      "Epoch 29/50, Training Loss: 0.8172999501228333, Validation Loss: 1.0324451625347137\n",
      "Epoch 30/50, Training Loss: 0.8580025672912598, Validation Loss: 1.0794513523578644\n",
      "Epoch 31/50, Training Loss: 0.8818769693374634, Validation Loss: 1.021945744752884\n",
      "Epoch 32/50, Training Loss: 0.7979724645614624, Validation Loss: 1.0332103073596954\n",
      "Epoch 33/50, Training Loss: 0.8062466502189636, Validation Loss: 1.064729392528534\n",
      "Epoch 34/50, Training Loss: 0.7928479790687561, Validation Loss: 1.0704086422920227\n",
      "Epoch 35/50, Training Loss: 0.7936910033226013, Validation Loss: 1.0634533166885376\n",
      "Epoch 36/50, Training Loss: 0.8181060194969177, Validation Loss: 1.0493051707744598\n",
      "Epoch 37/50, Training Loss: 0.7858992338180542, Validation Loss: 1.1352857053279877\n",
      "Epoch 38/50, Training Loss: 0.7677281260490417, Validation Loss: 1.0491714775562286\n",
      "Epoch 39/50, Training Loss: 0.7797067284584045, Validation Loss: 1.0297881066799164\n",
      "Epoch 40/50, Training Loss: 0.7680468440055848, Validation Loss: 1.0877264738082886\n",
      "Epoch 41/50, Training Loss: 0.725962471961975, Validation Loss: 1.0727814137935638\n",
      "Epoch 42/50, Training Loss: 0.7470261931419373, Validation Loss: 1.045981913805008\n",
      "Epoch 43/50, Training Loss: 0.7157758116722107, Validation Loss: 1.0979396998882294\n",
      "Epoch 44/50, Training Loss: 0.6959278583526611, Validation Loss: 1.0900232791900635\n",
      "Epoch 45/50, Training Loss: 0.6866008162498474, Validation Loss: 1.0648222267627716\n",
      "Epoch 46/50, Training Loss: 0.6927773475646972, Validation Loss: 1.1214111745357513\n",
      "Epoch 47/50, Training Loss: 0.6554272770881653, Validation Loss: 1.09771928191185\n",
      "Epoch 48/50, Training Loss: 0.6879384756088257, Validation Loss: 1.0990456342697144\n",
      "Epoch 49/50, Training Loss: 0.6595448136329651, Validation Loss: 1.0959344506263733\n",
      "Epoch 50/50, Training Loss: 0.6352735877037048, Validation Loss: 1.1512244641780853\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN(num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# Check if CUDA is available and move the model to the GPU if so\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "    \n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Map labels to the expected range (0-4)\n",
    "        labels = labels - 1\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate validation loss after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            \n",
    "            val_outputs = model(val_inputs)\n",
    "            \n",
    "            # Map validation labels to the expected range (0-4)\n",
    "            val_labels = val_labels - 1\n",
    "            \n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "    # Print training and validation loss\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b4c76a-0042-4237-a372-77657ff40323",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the model, loss function, and optimizer\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN(num_classes=5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 20\n",
    "\n",
    "# Check if CUDA is available and move the model to the GPU if so\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Lists to store training and validation losses and accuracies\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Map labels to the expected range (0-4)\n",
    "        labels = labels - 1\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Calculate validation loss and accuracy after each epoch\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            \n",
    "            val_outputs = model(val_inputs)\n",
    "            \n",
    "            # Map validation labels to the expected range (0-4)\n",
    "            val_labels = val_labels - 1\n",
    "            \n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            \n",
    "            _, predicted_val = torch.max(val_outputs.data, 1)\n",
    "            total_val += val_labels.size(0)\n",
    "            correct_val += (predicted_val == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Print training and validation loss and accuracy\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_losses[-1]}, Training Accuracy: {train_accuracies[-1]}%, Validation Loss: {val_losses[-1]}, Validation Accuracy: {val_accuracies[-1]}%\")\n",
    "\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "# Plot training and validation loss and accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235e67a-e64c-437e-990a-4ac0e7b8ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3d0f7-b78a-431e-ac79-3218269ec547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0861bc9-ecf1-4a40-9714-0af62eb1121e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-kjernel",
   "language": "python",
   "name": "torch-kjernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
